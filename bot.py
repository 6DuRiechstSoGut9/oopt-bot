import os
import logging
import threading
import time
import telebot
from flask import Flask
from waitress import serve
from dotenv import load_dotenv
import requests
import PyPDF2
import docx
import re

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

app = Flask(__name__)

@app.route('/')
def home():
    return "ü§ñ –ë–æ—Ç –û–û–ü–¢ –í–æ–ª–æ–≥–æ–¥—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç!"

TOKEN = os.getenv('TELEGRAM_TOKEN')
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')

if not TOKEN:
    logger.error("‚ùå TELEGRAM_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
    raise ValueError("TELEGRAM_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

bot = telebot.TeleBot(TOKEN)

class SimpleDocumentSearch:
    def __init__(self):
        self.documents = []
        self.loaded = False
        self.loading = False
        self.error = None
        
    def extract_text_from_file(self, file_path):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Ñ–∞–π–ª–æ–≤"""
        text = ""
        try:
            if file_path.endswith('.pdf'):
                with open(file_path, 'rb') as file:
                    reader = PyPDF2.PdfReader(file)
                    for page in reader.pages:
                        page_text = page.extract_text()
                        if page_text:
                            text += page_text + "\n"
            elif file_path.endswith('.docx'):
                doc = docx.Document(file_path)
                for paragraph in doc.paragraphs:
                    if paragraph.text:
                        text += paragraph.text + "\n"
            elif file_path.endswith('.txt'):
                with open(file_path, 'r', encoding='utf-8') as file:
                    text = file.read()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path}: {e}")
        return text
    
    def load_documents(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ –≤—Å–µ—Ö –ø–∞–ø–æ–∫"""
        self.loading = True
        self.error = None
        
        try:
            self.documents = []
            file_count = 0
            
            # –ò—â–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –≤–æ –≤—Å–µ—Ö –ø–∞–ø–∫–∞—Ö (–∫—Ä–æ–º–µ —Å–ª—É–∂–µ–±–Ω—ã—Ö)
            ignored_dirs = {'.git', '__pycache__', '.venv', 'venv'}
            allowed_extensions = ('.pdf', '.docx', '.txt')
            
            logger.info("üîç –ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤–æ –≤—Å–µ—Ö –ø–∞–ø–∫–∞—Ö...")
            
            for root, dirs, files in os.walk('.'):
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–∞–ø–∫–∏
                dirs[:] = [d for d in dirs if d not in ignored_dirs and not d.startswith('.')]
                
                for file in files:
                    if file.endswith(allowed_extensions):
                        file_path = os.path.join(root, file)
                        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã –≤ —Å–ª—É–∂–µ–±–Ω—ã—Ö –ø—É—Ç—è—Ö
                        if any(ignored in root for ignored in ignored_dirs):
                            continue
                            
                        logger.info(f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª: {file_path}")
                        
                        text = self.extract_text_from_file(file_path)
                        if text and len(text.strip()) > 10:
                            self.documents.append({
                                'file': file,
                                'path': file_path,
                                'text': text,
                                'size': len(text)
                            })
                            file_count += 1
                            logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω: {file} ({len(text)} —Å–∏–º–≤–æ–ª–æ–≤)")
                        else:
                            logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω (–º–∞–ª–æ —Ç–µ–∫—Å—Ç–∞): {file}")
            
            self.loaded = True
            logger.info(f"üéâ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {file_count}")
            
        except Exception as e:
            self.error = str(e)
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
        finally:
            self.loading = False
    
    def search_documents(self, query):
        """–£–º–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º"""
        if not self.loaded or not self.documents:
            return []
        
        query_lower = query.lower()
        results = []
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
        keywords = [word for word in query_lower.split() if len(word) > 2]
        
        for doc in self.documents:
            text_lower = doc['text'].lower()
            
            # –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            matches = sum(1 for word in keywords if word in text_lower)
            
            if matches > 0:
                # –ù–∞—Ö–æ–¥–∏–º –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç
                best_snippet = self.extract_best_snippet(doc['text'], keywords)
                
                results.append({
                    'file': doc['file'],
                    'path': doc['path'],
                    'snippet': best_snippet,
                    'full_text': doc['text'],
                    'score': matches
                })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        results.sort(key=lambda x: x['score'], reverse=True)
        return results[:3]
    
    def extract_best_snippet(self, text, keywords):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞"""
        sentences = re.split(r'[.!?]+', text)
        relevant_sentences = []
        
        for sentence in sentences:
            sentence_clean = sentence.strip()
            if len(sentence_clean) < 10:
                continue
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            sentence_lower = sentence_clean.lower()
            relevance = sum(1 for keyword in keywords if keyword in sentence_lower)
            
            if relevance > 0:
                relevant_sentences.append((sentence_clean, relevance))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ –±–µ—Ä–µ–º —Ç–æ–ø-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        relevant_sentences.sort(key=lambda x: x[1], reverse=True)
        best_sentences = [sentence for sentence, _ in relevant_sentences[:3]]
        
        return ". ".join(best_sentences) + "."
    
    def ask_deepseek(self, query, context):
        """–ó–∞–ø—Ä–æ—Å –∫ DeepSeek API"""
        if not DEEPSEEK_API_KEY:
            return None, "‚ùå API –∫–ª—é—á DeepSeek –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω."
        
        prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –û–û–ü–¢ –í–æ–ª–æ–≥–æ–¥—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å.

–ò–ù–§–û–†–ú–ê–¶–ò–Ø –ò–ó –î–û–ö–£–ú–ï–ù–¢–û–í:
{context}

–í–û–ü–†–û–°: {query}

–û—Ç–≤–µ—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —Å–æ–æ–±—â–∏ –æ–± —ç—Ç–æ–º."""

        try:
            headers = {
                "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": "deepseek-chat",
                "messages": [
                    {
                        "role": "system", 
                        "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –û–û–ü–¢ –í–æ–ª–æ–≥–æ–¥—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏. –û—Ç–≤–µ—á–∞–π —Ç–æ—á–Ω–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö."
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                "max_tokens": 800,
                "temperature": 0.3
            }
            
            response = requests.post(
                "https://api.deepseek.com/chat/completions",
                headers=headers,
                json=data,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['message']['content'], None
            else:
                return None, f"‚ùå –û—à–∏–±–∫–∞ API: {response.status_code}"
                
        except Exception as e:
            return None, f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {str(e)}"
    
    def generate_simple_answer(self, query, search_results):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –±–µ–∑ DeepSeek"""
        if not search_results:
            return self.get_no_results_message(query)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞
        query_lower = query.lower()
        
        if any(word in query_lower for word in ['–∑–∞–ø–æ–≤–µ–¥–Ω–∏–∫', '–∑–∞–∫–∞–∑–Ω–∏–∫', '–æ–æ–ø—Ç', '—Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏']):
            return self.generate_oopts_info(query, search_results)
        elif any(word in query_lower for word in ['—Ä–∞–π–æ–Ω', '–º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω', '–≥–¥–µ']):
            return self.generate_location_info(query, search_results)
        elif any(word in query_lower for word in ['—Å–∫–æ–ª—å–∫–æ', '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ', '—á–∏—Å–ª–æ']):
            return self.generate_count_info(query, search_results)
        else:
            return self.generate_general_info(query, search_results)
    
    def generate_oopts_info(self, query, search_results):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –û–û–ü–¢"""
        answer_parts = ["üåø **–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –û–û–ü–¢ –í–æ–ª–æ–≥–æ–¥—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏:**\n"]
        
        for result in search_results:
            file_name = result['file'].replace('.docx', '').replace('.pdf', '').replace('.txt', '')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ç–µ–∫—Å—Ç–∞
            text = result['full_text']
            
            # –ò—â–µ–º –ø—Ä–æ—Ñ–∏–ª—å
            profile_match = re.search(r'–ü—Ä–æ—Ñ–∏–ª—å\s*[‚Äî‚Äì:-]?\s*(.*?)(?:\n|$)', text, re.IGNORECASE)
            profile = profile_match.group(1).strip() if profile_match else "–Ω–µ —É–∫–∞–∑–∞–Ω"
            
            # –ò—â–µ–º —Ü–µ–ª–∏ —Å–æ–∑–¥–∞–Ω–∏—è
            goals_match = re.search(r'–¶–µ–ª–∏? —Å–æ–∑–¥–∞–Ω–∏—è?.*?[‚Äî‚Äì:-]?\s*(.*?)(?:\n|\.|$)', text, re.IGNORECASE)
            goals = goals_match.group(1).strip() if goals_match else "–Ω–µ —É–∫–∞–∑–∞–Ω—ã"
            
            # –ò—â–µ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
            restrictions_match = re.search(r'–∑–∞–ø—Ä–µ—â–∞—é—Ç—Å—è.*?:(.*?)(?:\n\n|\n\s*\n|$)', text, re.DOTALL)
            restrictions = restrictions_match.group(1).strip()[:200] + "..." if restrictions_match else "—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ä–µ–∂–∏–º –æ—Ö—Ä–∞–Ω—ã"
            
            info = f"""**üìã {file_name}**
‚Ä¢ **–ü—Ä–æ—Ñ–∏–ª—å:** {profile}
‚Ä¢ **–¶–µ–ª–∏:** {goals[:100]}...
‚Ä¢ **–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:** {restrictions}"""

            answer_parts.append(info)
        
        answer_parts.append(f"\nüìö *–ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ {len(search_results)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤*")
        return "\n\n".join(answer_parts)
    
    def generate_location_info(self, query, search_results):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–∏"""
        answer_parts = ["üó∫Ô∏è **–†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –û–û–ü–¢:**\n"]
        
        for result in search_results:
            file_name = result['file'].replace('.docx', '').replace('.pdf', '').replace('.txt', '')
            text = result['full_text']
            
            # –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —Ä–∞–π–æ–Ω–æ–≤
            districts = []
            common_districts = ['–í—ã—Ç–µ–≥–æ—Ä—Å–∫–∏–π', '–í–æ–ª–æ–≥–æ–¥—Å–∫–∏–π', '–ß–µ—Ä–µ–ø–æ–≤–µ—Ü–∫–∏–π', '–í–µ–ª–∏–∫–æ—É—Å—Ç—é–≥—Å–∫–∏–π', 
                              '–ë–∞–±–∞–µ–≤—Å–∫–∏–π', '–ö–∏—Ä–∏–ª–ª–æ–≤—Å–∫–∏–π', '–®–µ–∫—Å–Ω–∏–Ω—Å–∫–∏–π', '–£—Å—Ç—é–∂–µ–Ω—Å–∫–∏–π']
            
            for district in common_districts:
                if district.lower() in text.lower():
                    districts.append(district)
            
            location_info = f"**{file_name}**"
            if districts:
                location_info += f" - —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω –≤ {', '.join(districts)} —Ä–∞–π–æ–Ω–µ"
            else:
                location_info += " - —Ä–∞–π–æ–Ω —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—è –Ω–µ —É–∫–∞–∑–∞–Ω"
            
            answer_parts.append(location_info)
        
        return "\n‚Ä¢ ".join(answer_parts)
    
    def generate_count_info(self, query, search_results):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ"""
        total_docs = len(self.documents)
        return f"""üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –û–û–ü–¢:**

‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {total_docs}
‚Ä¢ –ù–∞–π–¥–µ–Ω–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É: {len(search_results)}
‚Ä¢ –û–±—â–∏–π –æ–±—ä–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {sum(doc['size'] for doc in self.documents):,} —Å–∏–º–≤–æ–ª–æ–≤

üí° *–î–ª—è —Ç–æ—á–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –û–û–ü–¢*"""
    
    def generate_general_info(self, query, search_results):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—â–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
        answer_parts = [f"üîç **–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∑–∞–ø—Ä–æ—Å—É '{query}':**\n"]
        
        for i, result in enumerate(search_results, 1):
            file_name = result['file'].replace('.docx', '').replace('.pdf', '').replace('.txt', '')
            snippet = result['snippet']
            
            # –û–±—Ä–µ–∑–∞–µ–º —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ —Å–Ω–∏–ø–ø–µ—Ç—ã
            if len(snippet) > 300:
                snippet = snippet[:300] + "..."
            
            answer_parts.append(f"{i}. **{file_name}**\n{snippet}")
        
        return "\n\n".join(answer_parts)
    
    def get_no_results_message(self, query):
        """–°–æ–æ–±—â–µ–Ω–∏–µ –∫–æ–≥–¥–∞ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"""
        return f"""‚ùå –ü–æ –∑–∞–ø—Ä–æ—Å—É "{query}" –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.

üí° **–°–æ–≤–µ—Ç—ã –¥–ª—è –ø–æ–∏—Å–∫–∞:**
‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –û–û–ü–¢
‚Ä¢ –£–∫–∞–∑—ã–≤–∞–π—Ç–µ —Ä–∞–π–æ–Ω—ã –í–æ–ª–æ–≥–æ–¥—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏  
‚Ä¢ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ: "–∑–∞–∫–∞–∑–Ω–∏–∫–∏", "–ø–∞–º—è—Ç–Ω–∏–∫–∏ –ø—Ä–∏—Ä–æ–¥—ã", "–í—ã—Ç–µ–≥–æ—Ä—Å–∫–∏–π —Ä–∞–π–æ–Ω"

üìã **–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:**
/files - —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
/help - —Å–ø—Ä–∞–≤–∫–∞ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é"""

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã
doc_search = SimpleDocumentSearch()

def initialize_documents():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
    logger.info("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤–æ –≤—Å–µ—Ö –ø–∞–ø–∫–∞—Ö...")
    doc_search.load_documents()
    
    if doc_search.loaded:
        logger.info(f"üéâ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(doc_search.documents)}")
    elif doc_search.error:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {doc_search.error}")
    else:
        logger.warning("‚ö†Ô∏è –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –ø–æ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–π –ø—Ä–∏—á–∏–Ω–µ")

# –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é
logger.info("üöÄ –ó–∞–ø—É—Å–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
doc_thread = threading.Thread(target=initialize_documents, daemon=True)
doc_thread.start()

@bot.message_handler(commands=['start', 'help'])
def send_welcome(message):
    welcome_text = """ü§ñ –ë–æ—Ç –û–û–ü–¢ –í–æ–ª–æ–≥–æ–¥—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏

üìö **–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –æ–± –û—Å–æ–±–æ –û—Ö—Ä–∞–Ω—è–µ–º—ã—Ö –ü—Ä–∏—Ä–æ–¥–Ω—ã—Ö –¢–µ—Ä—Ä–∏—Ç–æ—Ä–∏—è—Ö**

üîç **–ö–∞–∫ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –±–æ—Ç–æ–º:**
‚Ä¢ –ó–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ
‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –û–û–ü–¢
‚Ä¢ –£–∫–∞–∑—ã–≤–∞–π—Ç–µ —Ä–∞–π–æ–Ω—ã –í–æ–ª–æ–≥–æ–¥—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏

üí° **–ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤:**
‚Ä¢ "–ó–∞–ø–æ–≤–µ–¥–Ω–∏–∫–∏ –∏ –∑–∞–∫–∞–∑–Ω–∏–∫–∏"
‚Ä¢ "–û–û–ü–¢ –í—ã—Ç–µ–≥–æ—Ä—Å–∫–æ–≥–æ —Ä–∞–π–æ–Ω–∞" 
‚Ä¢ "–ü–∞–º—è—Ç–Ω–∏–∫–∏ –ø—Ä–∏—Ä–æ–¥—ã"
‚Ä¢ "–°–∫–æ–ª—å–∫–æ –≤—Å–µ–≥–æ –æ—Ö—Ä–∞–Ω—è–µ–º—ã—Ö —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–π"

üìã **–ö–æ–º–∞–Ω–¥—ã:**
/start –∏–ª–∏ /help - —ç—Ç–∞ —Å–ø—Ä–∞–≤–∫–∞
/status - —Å—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã
/files - —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
/mode - —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã"""

    bot.reply_to(message, welcome_text)

@bot.message_handler(commands=['status'])
def send_status(message):
    if doc_search.loading:
        status_text = "üîÑ **–ò–¥–µ—Ç –ø–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...**\n–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ."
    elif doc_search.loaded:
        status_text = f"""‚úÖ **–°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!**

‚Ä¢ –ù–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(doc_search.documents)}
‚Ä¢ –û–±—â–∏–π –æ–±—ä–µ–º —Ç–µ–∫—Å—Ç–∞: {sum(doc['size'] for doc in doc_search.documents):,} —Å–∏–º–≤–æ–ª–æ–≤
‚Ä¢ DeepSeek API: {'‚úÖ –ù–∞—Å—Ç—Ä–æ–µ–Ω' if DEEPSEEK_API_KEY else '‚ùå –ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω'}
‚Ä¢ –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã: {'ü§ñ –° DeepSeek' if DEEPSEEK_API_KEY else 'üìö –£–º–Ω—ã–π –ø–æ–∏—Å–∫'}"""
    elif doc_search.error:
        status_text = f"""‚ùå **–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏**

‚Ä¢ –û—à–∏–±–∫–∞: {doc_search.error}"""
    else:
        status_text = "‚ö™ **–°—Ç–∞—Ç—É—Å –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω**"
    
    bot.reply_to(message, status_text)

@bot.message_handler(commands=['mode'])
def show_mode(message):
    """–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–π —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã"""
    if DEEPSEEK_API_KEY:
        mode_text = """ü§ñ **–†–µ–∂–∏–º: –° DeepSeek**

–ë–æ—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç DeepSeek AI –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."""
    else:
        mode_text = """üìö **–†–µ–∂–∏–º: –£–º–Ω—ã–π –ø–æ–∏—Å–∫**

–ë–æ—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é:
‚Ä¢ –û—Å–Ω–æ–≤–Ω—ã–µ —Å–≤–µ–¥–µ–Ω–∏—è –æ–± –û–û–ü–¢
‚Ä¢ –†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –∏ —Ä–∞–π–æ–Ω—ã
‚Ä¢ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ –æ–±—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é"""
    
    bot.reply_to(message, mode_text)

@bot.message_handler(commands=['files'])
def list_files(message):
    """–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    if not doc_search.loaded:
        bot.reply_to(message, "‚ùå –î–æ–∫—É–º–µ–Ω—Ç—ã –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")
        return
    
    if not doc_search.documents:
        bot.reply_to(message, "‚ùå –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        return
    
    files_text = "üìÅ **–ù–∞–π–¥–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã:**\n\n"
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø–µ—Ä–≤—ã–º —Ü–∏—Ñ—Ä–∞–º (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—è —á—Ç–æ —ç—Ç–æ –Ω–æ–º–µ—Ä–∞ –û–û–ü–¢)
    grouped_files = {}
    for doc in doc_search.documents:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
        match = re.match(r'(\d+)', doc['file'])
        if match:
            prefix = match.group(1)
        else:
            prefix = 'ÂÖ∂‰ªñ'
        
        if prefix not in grouped_files:
            grouped_files[prefix] = []
        grouped_files[prefix].append(doc)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–æ–º–µ—Ä–∞–º
    for prefix in sorted(grouped_files.keys(), key=lambda x: int(x) if x.isdigit() else 999):
        files = grouped_files[prefix]
        files_text += f"**{prefix}xx:**\n"
        for doc in files[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 —Ñ–∞–π–ª–æ–≤ –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã
            files_text += f"‚Ä¢ {doc['file']} ({doc['size']:,} —Å–∏–º–≤–æ–ª–æ–≤)\n"
        if len(files) > 5:
            files_text += f"  ... –∏ –µ—â–µ {len(files) - 5} —Ñ–∞–π–ª–æ–≤\n"
        files_text += "\n"
    
    files_text += f"üìä –í—Å–µ–≥–æ: {len(doc_search.documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"
    
    bot.reply_to(message, files_text)

@bot.message_handler(func=lambda message: True)
def handle_message(message):
    bot.send_chat_action(message.chat.id, 'typing')
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏
    if doc_search.loading:
        bot.reply_to(message, "üîÑ –î–æ–∫—É–º–µ–Ω—Ç—ã –µ—â–µ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ 30 —Å–µ–∫—É–Ω–¥.")
        return
    
    if not doc_search.loaded:
        if doc_search.error:
            bot.reply_to(message, f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {doc_search.error}")
        else:
            bot.reply_to(message, "‚ùå –î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")
        return
    
    user_query = message.text.strip()
    
    if len(user_query) < 2:
        bot.reply_to(message, "‚ùå –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –∑–∞–ø—Ä–æ—Å.")
        return
    
    # –ò—â–µ–º –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö
    search_results = doc_search.search_documents(user_query)
    
    if not search_results:
        answer = doc_search.get_no_results_message(user_query)
        bot.reply_to(message, answer)
        return
    
    # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å DeepSeek –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
    if DEEPSEEK_API_KEY:
        # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = "\n\n".join([
            f"–ò–∑ {result['file']}:\n{result['snippet']}" 
            for result in search_results
        ])
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ DeepSeek
        deepseek_answer, error = doc_search.ask_deepseek(user_query, context)
        
        if deepseek_answer:
            # –£—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç DeepSeek
            sources = ", ".join(set(result['file'] for result in search_results))
            full_answer = f"{deepseek_answer}\n\nüìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {sources}"
        else:
            # –û—à–∏–±–∫–∞ DeepSeek - –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–º–Ω—ã–π –ø–æ–∏—Å–∫
            logger.warning(f"DeepSeek –æ—à–∏–±–∫–∞: {error}")
            simple_answer = doc_search.generate_simple_answer(user_query, search_results)
            sources = ", ".join(set(result['file'] for result in search_results))
            full_answer = f"{simple_answer}\n\nüìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {sources}"
    else:
        # –†–µ–∂–∏–º —É–º–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
        simple_answer = doc_search.generate_simple_answer(user_query, search_results)
        sources = ", ".join(set(result['file'] for result in search_results))
        full_answer = f"{simple_answer}\n\nüìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {sources}"
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
    try:
        if len(full_answer) > 4000:
            parts = [full_answer[i:i+4000] for i in range(0, len(full_answer), 4000)]
            for part in parts:
                bot.reply_to(message, part)
        else:
            bot.reply_to(message, full_answer)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        bot.reply_to(message, "‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –æ—Ç–≤–µ—Ç–∞.")

def main():
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ –Ω–∞ Python 3.13.4...")
    
    # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –Ω–∞—á–∞–ª—å–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    logger.info("‚è≥ –û–∂–∏–¥–∞–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –Ω–∞—á–∞–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
    for i in range(30):
        if doc_search.loaded or doc_search.error:
            break
        time.sleep(1)
    
    if doc_search.loaded:
        logger.info(f"üéâ –ù–∞—á–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(doc_search.documents)}")
    elif doc_search.error:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—á–∞–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏: {doc_search.error}")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞
    threading.Thread(target=bot.infinity_polling, daemon=True).start()
    logger.info("‚úÖ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω. –ó–∞–ø—É—Å–∫–∞–µ–º –≤–µ–±-—Å–µ—Ä–≤–µ—Ä...")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤–µ–±-—Å–µ—Ä–≤–µ—Ä
    serve(app, host='0.0.0.0', port=8000)

if __name__ == '__main__':
    main()
